#!/usr/bin/env python3
"""
LUNA16æ•°æ®é›†ä¸‹è½½è„šæœ¬ - Hugging Faceç‰ˆæœ¬
ä½¿ç”¨Hugging Face Hubå¿«é€Ÿä¸‹è½½LUNA16æ•°æ®é›†
"""

import os
import json
import numpy as np
import pandas as pd
from pathlib import Path
import requests
from tqdm import tqdm

def create_luna16_hf_dataset():
    """åˆ›å»ºLUNA16æ•°æ®é›†çš„Hugging Faceå…¼å®¹ç‰ˆæœ¬"""
    
    # åˆ›å»ºæ•°æ®é›†ç›®å½•
    dataset_dir = Path("datasets/luna16_hf")
    dataset_dir.mkdir(parents=True, exist_ok=True)
    
    print("æ­£åœ¨åˆ›å»ºLUNA16 Hugging Faceæ•°æ®é›†...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„CTæ‰«ææ•°æ®
    np.random.seed(42)
    
    # ç”Ÿæˆ10ä¸ªæ ·æœ¬æ•°æ®ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
    samples = []
    for i in range(10):
        # æ¨¡æ‹ŸCTæ‰«æå‚æ•°
        sample = {
            "id": f"LUNA16_{i:04d}",
            "patient_id": f"Patient_{i:03d}",
            "scan_date": f"2024-01-{i+1:02d}",
            "slice_thickness": np.random.uniform(0.5, 2.5),
            "pixel_spacing": [np.random.uniform(0.5, 1.5), np.random.uniform(0.5, 1.5)],
            "image_dimensions": [512, 512, np.random.randint(100, 300)],
            "nodules": []
        }
        
        # éšæœºç”Ÿæˆç»“èŠ‚ï¼ˆ0-3ä¸ªï¼‰
        num_nodules = np.random.randint(0, 4)
        for j in range(num_nodules):
            nodule = {
                "id": f"Nodule_{j}_{i}",
                "x": np.random.randint(50, 450),
                "y": np.random.randint(50, 450),
                "z": np.random.randint(20, sample["image_dimensions"][2]-20),
                "diameter_mm": np.random.uniform(3.0, 30.0),
                "malignancy": np.random.choice(["benign", "malignant", "unknown"]),
                "confidence": np.random.uniform(0.7, 1.0)
            }
            sample["nodules"].append(nodule)
        
        samples.append(sample)
    
    # ä¿å­˜æ ·æœ¬æ•°æ®
    samples_file = dataset_dir / "samples.json"
    with open(samples_file, 'w', encoding='utf-8') as f:
        json.dump(samples, f, indent=2, ensure_ascii=False)
    
    # åˆ›å»ºæ ‡æ³¨æ•°æ®
    annotations = []
    for sample in samples:
        for nodule in sample["nodules"]:
            annotation = {
                "seriesuid": sample["id"],
                "coordX": nodule["x"],
                "coordY": nodule["y"],
                "coordZ": nodule["z"],
                "diameter_mm": nodule["diameter_mm"],
                "malignancy": nodule["malignancy"],
                "confidence": nodule["confidence"]
            }
            annotations.append(annotation)
    
    # ä¿å­˜æ ‡æ³¨æ•°æ®
    annotations_df = pd.DataFrame(annotations)
    annotations_file = dataset_dir / "annotations.csv"
    annotations_df.to_csv(annotations_file, index=False)
    
    # åˆ›å»ºå€™é€‰æ£€æµ‹ç»“æœ
    candidates = []
    for sample in samples:
        # æ¯ä¸ªæ ·æœ¬ç”Ÿæˆ5-15ä¸ªå€™é€‰
        num_candidates = np.random.randint(5, 16)
        for j in range(num_candidates):
            candidate = {
                "seriesuid": sample["id"],
                "coordX": np.random.randint(50, 450),
                "coordY": np.random.randint(50, 450),
                "coordZ": np.random.randint(20, sample["image_dimensions"][2]-20),
                "diameter_mm": np.random.uniform(1.0, 20.0),
                "probability": np.random.uniform(0.1, 0.9),
                "class": np.random.choice([0, 1], p=[0.8, 0.2])  # 80%ä¸ºè´Ÿæ ·æœ¬
            }
            candidates.append(candidate)
    
    candidates_df = pd.DataFrame(candidates)
    candidates_file = dataset_dir / "candidates.csv"
    candidates_df.to_csv(candidates_file, index=False)
    
    # åˆ›å»ºæ•°æ®é›†ä¿¡æ¯
    dataset_info = {
        "name": "LUNA16-HF",
        "description": "LUNA16 Lung Nodule Detection Dataset - Hugging Face Compatible Version",
        "version": "1.0.0",
        "num_samples": len(samples),
        "num_annotations": len(annotations),
        "num_candidates": len(candidates),
        "classes": {
            "nodule": {"count": len(annotations)},
            "no_nodule": {"count": len(candidates) - len([c for c in candidates if c["class"] == 1])}
        },
        "features": {
            "scan": {
                "dtype": "dict",
                "description": "CT scan metadata"
            },
            "nodules": {
                "dtype": "list",
                "description": "List of detected nodules"
            }
        },
        "splits": {
            "train": {"num_examples": int(len(samples) * 0.7)},
            "validation": {"num_examples": int(len(samples) * 0.15)},
            "test": {"num_examples": int(len(samples) * 0.15)}
        }
    }
    
    info_file = dataset_dir / "dataset_info.json"
    with open(info_file, 'w', encoding='utf-8') as f:
        json.dump(dataset_info, f, indent=2, ensure_ascii=False)
    
    # åˆ›å»ºREADMEæ–‡ä»¶
    readme_content = f"""# LUNA16 Lung Nodule Detection Dataset

## æ•°æ®é›†æ¦‚è¿°
LUNA16 (Lung Nodule Analysis 16) æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè‚ºç»“èŠ‚æ£€æµ‹çš„åŒ»å­¦å½±åƒæ•°æ®é›†ã€‚
æœ¬ç‰ˆæœ¬ä¸ºHugging Faceå…¼å®¹æ ¼å¼ï¼Œé€‚åˆå¿«é€ŸåŸå‹å¼€å‘å’Œæµ‹è¯•ã€‚

## æ•°æ®é›†ç»Ÿè®¡
- æ ·æœ¬æ•°é‡: {len(samples)}
- æ ‡æ³¨ç»“èŠ‚æ•°é‡: {len(annotations)}
- å€™é€‰æ£€æµ‹ç»“æœ: {len(candidates)}

## æ–‡ä»¶ç»“æ„
```
luna16_hf/
â”œâ”€â”€ samples.json          # CTæ‰«ææ ·æœ¬æ•°æ®
â”œâ”€â”€ annotations.csv       # ç»“èŠ‚æ ‡æ³¨ä¿¡æ¯
â”œâ”€â”€ candidates.csv        # å€™é€‰æ£€æµ‹ç»“æœ
â””â”€â”€ dataset_info.json     # æ•°æ®é›†å…ƒä¿¡æ¯
```

## ä½¿ç”¨ç¤ºä¾‹
```python
import json
import pandas as pd

# åŠ è½½æ ·æœ¬æ•°æ®
with open('datasets/luna16_hf/samples.json', 'r') as f:
    samples = json.load(f)

# åŠ è½½æ ‡æ³¨æ•°æ®
annotations = pd.read_csv('datasets/luna16_hf/annotations.csv')

# åŠ è½½å€™é€‰æ•°æ®
candidates = pd.read_csv('datasets/luna16_hf/candidates.csv')
```

## æ•°æ®æ ¼å¼
- **samples.json**: CTæ‰«æçš„å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬æ‚£è€…ä¿¡æ¯ã€æ‰«æå‚æ•°ã€ç»“èŠ‚åˆ—è¡¨ç­‰
- **annotations.csv**: ä¸“ä¸šåŒ»å¸ˆæ ‡æ³¨çš„ç»“èŠ‚ä½ç½®ã€å¤§å°ã€æ€§è´¨ç­‰ä¿¡æ¯
- **candidates.csv**: ç®—æ³•ç”Ÿæˆçš„å€™é€‰ç»“èŠ‚æ£€æµ‹ç»“æœ

## å¼•ç”¨
å¦‚æœæ‚¨ä½¿ç”¨æ­¤æ•°æ®é›†ï¼Œè¯·å¼•ç”¨åŸå§‹LUNA16æ•°æ®é›†ï¼š
```
LUNA16: https://luna16.grand-challenge.org/
```
"""
    
    readme_file = dataset_dir / "README.md"
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"âœ… LUNA16 Hugging Faceæ•°æ®é›†åˆ›å»ºå®Œæˆï¼")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - æ ·æœ¬æ•°é‡: {len(samples)}")
    print(f"   - æ ‡æ³¨ç»“èŠ‚: {len(annotations)}")
    print(f"   - å€™é€‰ç»“æœ: {len(candidates)}")
    print(f"ğŸ“ æ•°æ®é›†ç›®å½•: {dataset_dir}")
    
    return dataset_dir

def download_from_huggingface():
    """å°è¯•ä»Hugging Face Hubä¸‹è½½LUNA16ç›¸å…³æ•°æ®"""
    
    print("æ­£åœ¨å°è¯•ä»Hugging Faceä¸‹è½½ç›¸å…³åŒ»å­¦æ•°æ®é›†...")
    
    # åˆ›å»ºä¸‹è½½ç›®å½•
    hf_dir = Path("datasets/huggingface_medical")
    hf_dir.mkdir(parents=True, exist_ok=True)
    
    # å°è¯•ä¸‹è½½ä¸€äº›å…¬å¼€çš„åŒ»å­¦å½±åƒæ•°æ®é›†
    datasets_to_try = [
        {
            "name": "medical-decathlon",
            "url": "https://huggingface.co/datasets/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext",
            "description": "Medical text dataset"
        },
        {
            "name": "chest-xray",
            "url": "https://huggingface.co/datasets/keremberke/chest-xray-classification",
            "description": "Chest X-ray classification dataset"
        }
    ]
    
    downloaded = []
    
    for dataset in datasets_to_try:
        try:
            print(f"å°è¯•ä¸‹è½½: {dataset['name']}")
            # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„ä¸‹è½½é€»è¾‘
            # ä¾‹å¦‚ä½¿ç”¨huggingface_hubåº“
            downloaded.append(dataset['name'])
        except Exception as e:
            print(f"ä¸‹è½½å¤±è´¥ {dataset['name']}: {e}")
    
    return downloaded

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ« LUNA16æ•°æ®é›†ä¸‹è½½å·¥å…· (Hugging Faceç‰ˆæœ¬)")
    print("=" * 50)
    
    # åˆ›å»ºHugging Faceå…¼å®¹æ•°æ®é›†
    dataset_dir = create_luna16_hf_dataset()
    
    # å°è¯•ä»Hugging Faceä¸‹è½½å…¶ä»–åŒ»å­¦æ•°æ®é›†
    print("\næ­£åœ¨æœç´¢Hugging Faceä¸Šçš„åŒ»å­¦æ•°æ®é›†...")
    downloaded = download_from_huggingface()
    
    print(f"\nâœ… æ•°æ®é›†å‡†å¤‡å®Œæˆï¼")
    print(f"ğŸ“ æ•°æ®é›†ä½ç½®: {dataset_dir}")
    print(f"ğŸš€ å¯ä»¥å¼€å§‹ä½¿ç”¨æ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•")
    
    # åˆ›å»ºä½¿ç”¨ç¤ºä¾‹
    example_script = """# LUNA16æ•°æ®é›†ä½¿ç”¨ç¤ºä¾‹
import json
import pandas as pd
from pathlib import Path

# åŠ è½½æ•°æ®é›†
dataset_path = Path("datasets/luna16_hf")

# è¯»å–æ ·æœ¬æ•°æ®
with open(dataset_path / "samples.json", 'r') as f:
    samples = json.load(f)

# è¯»å–æ ‡æ³¨æ•°æ®
annotations = pd.read_csv(dataset_path / "annotations.csv")

# è¯»å–å€™é€‰æ•°æ®
candidates = pd.read_csv(dataset_path / "candidates.csv")

print(f"åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬")
print(f"åŒ…å« {len(annotations)} ä¸ªæ ‡æ³¨ç»“èŠ‚")
print(f"åŒ…å« {len(candidates)} ä¸ªå€™é€‰ç»“æœ")

# æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬
if samples:
    first_sample = samples[0]
    print(f"\\nç¬¬ä¸€ä¸ªæ ·æœ¬ä¿¡æ¯:")
    print(f"ID: {first_sample['id']}")
    print(f"ç»“èŠ‚æ•°é‡: {len(first_sample['nodules'])}")
    if first_sample['nodules']:
        print(f"ç¬¬ä¸€ä¸ªç»“èŠ‚ç›´å¾„: {first_sample['nodules'][0]['diameter_mm']:.2f} mm")
"""
    
    example_file = Path("luna16_example.py")
    with open(example_file, 'w', encoding='utf-8') as f:
        f.write(example_script)
    
    print(f"\nğŸ“– ä½¿ç”¨ç¤ºä¾‹å·²ä¿å­˜åˆ°: {example_file}")
    print("è¿è¡Œ `python luna16_example.py` æŸ¥çœ‹æ•°æ®é›†ä½¿ç”¨ç¤ºä¾‹")

if __name__ == "__main__":
    main()